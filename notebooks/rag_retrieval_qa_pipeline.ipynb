{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c89a4cf5",
   "metadata": {},
   "source": [
    "# ğŸ§  RAG ê¸°ë°˜ ì „ì„¸ì‚¬ê¸°í”¼í•´ ë²•ë¥  ìƒë‹´ QA íŒŒì´í”„ë¼ì¸\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ **ë²•ë¥  ë¬¸ì„œ(`law_1.docx`, `law_2.docx`)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ Retrieval-Augmented Generation (RAG)** íŒŒì´í”„ë¼ì¸ì„ êµ¬í˜„í•©ë‹ˆë‹¤.  \n",
    "í”„ë¡œì„¸ìŠ¤ëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤:\n",
    "\n",
    "1. ë¬¸ì„œ ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
    "2. ì„ë² ë”© ë° ë²¡í„°ìŠ¤í† ì–´ ìƒì„±\n",
    "3. RetrievalQA êµ¬í˜„\n",
    "\n",
    "> **[ëª©í‘œ]**  \n",
    "> ë²•ë¥  ë¬¸ì„œë¥¼ ìë™ìœ¼ë¡œ ê²€ìƒ‰Â·ìš”ì•½í•˜ì—¬ ì „ì„¸ì‚¬ê¸° ê´€ë ¨ ë²•ë¥  ì¡°ì–¸ì„ ì œê³µí•˜ëŠ”  \n",
    "> RAG ê¸°ë°˜ ì±—ë´‡ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a154d941",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hi\\AppData\\Local\\miniconda3\\envs\\project\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ì „ì„¸ì‚¬ê¸°í”¼í•´ì ì„ëŒ€ì¸ì€ íŠ¹ë³„ë²•ì—ì„œ \"ì„ëŒ€ì¸\"ìœ¼ë¡œ ì •ì˜ëœ ì¸ë¬¼ì´ë‚˜ ê¸°ê´€ì„ ë§í•˜ë©°, ì‹¤ì œë¡œ ì£¼íƒì˜ ì„ëŒ€ì— ê´€ë ¨ëœ ì—…ë¬´ë¥¼ ì²˜ë¦¬í•˜ê±°ë‚˜ ì„ëŒ€ì¸ì„ ëŒ€ë¦¬í•˜ëŠ” ì, ì„ëŒ€ì¸ì„ ìœ„í•œ ì¤‘ê°œì—…ì ë“±ì´ í¬í•¨ë©ë‹ˆë‹¤. ë˜í•œ, ë‹¤ìˆ˜ ì„ëŒ€ì¸ì˜ ë°°í›„ì— ìˆëŠ” ë™ì¼ì¸ì´ë‚˜ ì´ë¥¼ ì§€ë°°í•˜ëŠ” ì¡°ì§ë„ í¬í•¨ë©ë‹ˆë‹¤. ì¶”ê°€ë¡œ, ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„ëŒ€ì°¨ ê³„ì•½ì„ ë§ºì€ ìë‚˜ ê·¸ ì¡°ì§ë„ ì „ì„¸ì‚¬ê¸°í”¼í•´ìë²•ì—ì„œ ì •ì˜í•˜ëŠ” ì„ëŒ€ì¸ìœ¼ë¡œ ê°„ì£¼ë©ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pinecone import Pinecone\n",
    "\n",
    "\n",
    "## í™˜ê²½ë³€ìˆ˜ ì½ì–´ì˜¤ê¸°\n",
    "load_dotenv()\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "LANGCHAIN_API_KEY = os.getenv('LANGCHAIN_API_KEY')\n",
    "\n",
    "## ë¬¸ì„œ ì½ê³  ë¶„í•  ##################################\n",
    "## ë¬¸ì„œ íŒŒì¼ ëª©ë¡\n",
    "# doc_paths = ['law_1.docx', 'law_2.docx']\n",
    "\n",
    "# ## ë¬¸ì„œ ë¡œë“œ(ì½ì–´ì˜¤ê¸°)\n",
    "# documents = []\n",
    "\n",
    "# for path in doc_paths:\n",
    "#     loader = Docx2txtLoader(path)\n",
    "#     documents.extend(loader.load())\n",
    "\n",
    "# ## ì²­í¬ ë¶„í•  ì„¤ì •\n",
    "# text_splitter = RecursiveCharacterTextSplitter(\n",
    "#     chunk_size=1500,\n",
    "#     chunk_overlap=200,\n",
    "# )\n",
    "\n",
    "# ## ë¬¸ì„œ ë¶„í• \n",
    "# document_list = text_splitter.split_documents(documents)\n",
    "\n",
    "\n",
    "## ì„ë² ë”© -> ë²¡í„° ìŠ¤í† ì–´(ë°ì´í„°ë² ì´ìŠ¤)ì— ì €ì¥\n",
    "## ì„ë² ë”© ëª¨ë¸ ì§€ì •\n",
    "embedding = OpenAIEmbeddings(model='text-embedding-3-large')\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index_name = 'law'\n",
    "\n",
    "## íŒŒì¸ì½˜: ì €ì¥\n",
    "# database =  PineconeVectorStore.from_documents(\n",
    "#     documents=document_list,\n",
    "#     embedding=embedding,\n",
    "#     index_name=index_name,\n",
    "# )\n",
    "\n",
    "## ì €ì¥ëœ ì¸ë±ìŠ¤ ê°€ì ¸ì˜¤ê¸°\n",
    "## [ë°©ë²• 1]\n",
    "# database = PineconeVectorStore(\n",
    "#     index=pc.Index(index_name),\n",
    "#     embedding=embedding,\n",
    "# )\n",
    "\n",
    "## [ë°©ë²• 2]\n",
    "database = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embedding,\n",
    ")\n",
    "\n",
    "## RetrievalQA\n",
    "llm = ChatOpenAI(model='gpt-4o')\n",
    "prompt = hub.pull('rlm/rag-prompt')\n",
    "\n",
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join(doc.page_content for doc in docs)\n",
    "\n",
    "qa_chain = (\n",
    "    {\n",
    "        'context': database.as_retriever() | format_docs,\n",
    "        'question': RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# qa_chain.invoke('ì „ì„¸ì‚¬ê¸°í”¼í•´ì ëŒ€ìƒì„ ì•Œë ¤ì£¼ì„¸ìš”.')\n",
    "qa_chain.invoke('ì „ì„¸ì‚¬ê¸°í”¼í•´ì ì„ëŒ€ì¸ì„ ì•Œë ¤ì£¼ì„¸ìš”.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38d0b065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                         Type                   Data/Info\n",
      "-----------------------------------------------------------------\n",
      "ChatOpenAI                       ModelMetaclass         <class 'langchain_openai.<...>_models.base.ChatOpenAI'>\n",
      "Docx2txtLoader                   ABCMeta                <class 'langchain_communi<...>document.Docx2txtLoader'>\n",
      "LANGCHAIN_API_KEY                str                    lsv2_pt_4c2ea048f4b64e489<...>100e74f13518f9_2579b3041d\n",
      "OpenAIEmbeddings                 ModelMetaclass         <class 'langchain_openai.<...>s.base.OpenAIEmbeddings'>\n",
      "PINECONE_API_KEY                 str                    pcsk_2v8RCj_2EuL5eWhJori2<...>a2uBh6NhmcE7rivqJVefzeZR3\n",
      "Pinecone                         ABCMeta                <class 'pinecone.control.pinecone.Pinecone'>\n",
      "PineconeVectorStore              ABCMeta                <class 'langchain_pinecon<...>res.PineconeVectorStore'>\n",
      "RecursiveCharacterTextSplitter   ABCMeta                <class 'langchain_text_sp<...>veCharacterTextSplitter'>\n",
      "RunnablePassthrough              ModelMetaclass         <class 'langchain_core.ru<...>ugh.RunnablePassthrough'>\n",
      "StrOutputParser                  ModelMetaclass         <class 'langchain_core.ou<...>.string.StrOutputParser'>\n",
      "database                         PineconeVectorStore    <langchain_pinecone.vecto<...>ct at 0x0000021146067A30>\n",
      "embedding                        OpenAIEmbeddings       client=<openai.resources.<...>embedding_ctx_length=True\n",
      "format_docs                      function               <function format_docs at 0x0000021154819FC0>\n",
      "hub                              module                 <module 'langchain.hub' f<...>ages\\\\langchain\\\\hub.py'>\n",
      "index_name                       str                    law\n",
      "llm                              ChatOpenAI             client=<openai.resources.<...>y=SecretStr('**********')\n",
      "load_dotenv                      function               <function load_dotenv at 0x0000021146086320>\n",
      "os                               module                 <module 'os' from 'c:\\\\Us<...>vs\\\\project\\\\lib\\\\os.py'>\n",
      "pc                               Pinecone               <pinecone.control.pinecon<...>ct at 0x0000021147A41BA0>\n",
      "prompt                           ChatPromptTemplate     input_variables=['context<...>), additional_kwargs={})]\n",
      "qa_chain                         RunnableSequence       first={\\n  context: Vecto<...>)] last=StrOutputParser()\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e535007d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone\n",
    "\n",
    "\n",
    "## í™˜ê²½ë³€ìˆ˜ ì½ì–´ì˜¤ê¸° ############################################\n",
    "load_dotenv()\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "LANGCHAIN_API_KEY = os.getenv('LANGCHAIN_API_KEY')\n",
    "\n",
    "## ë²¡í„° ìŠ¤í† ì–´(ë°ì´í„°ë² ì´ìŠ¤)ì—ì„œ ì¸ë±ìŠ¤ ê°€ì ¸ì˜¤ê¸° ###############\n",
    "## ì„ë² ë”© ëª¨ë¸ ì§€ì •\n",
    "embedding = OpenAIEmbeddings(model='text-embedding-3-large')\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index_name = 'law'\n",
    "\n",
    "## ì €ì¥ëœ ì¸ë±ìŠ¤ ê°€ì ¸ì˜¤ê¸°\n",
    "database = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embedding,\n",
    ")\n",
    "\n",
    "## RetrievalQA ##################################################\n",
    "llm = ChatOpenAI(model='gpt-4o')\n",
    "prompt = hub.pull('rlm/rag-prompt')\n",
    "\n",
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join(doc.page_content for doc in docs)\n",
    "\n",
    "qa_chain = (\n",
    "    {\n",
    "        'context': database.as_retriever() | format_docs,\n",
    "        'question': RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# qa_chain.invoke('ì „ì„¸ì‚¬ê¸°í”¼í•´ì ëŒ€ìƒì„ ì•Œë ¤ì£¼ì„¸ìš”.')\n",
    "qa_chain.invoke('ì „ì„¸ì‚¬ê¸°í”¼í•´ì ì„ëŒ€ì¸ì„ ì•Œë ¤ì£¼ì„¸ìš”.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
